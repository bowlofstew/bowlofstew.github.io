---
layout: post
title: 09-01-2016 Check-In
comments: true
permalink: 09012016-check-in
tags:
  - Daily
  - Presto
  - Spark
  - Scala
  - DCOS
---

<div><!-- <a href="https://twitter.com/share" class="twitter-share-button" data-via="__shenderson__">Tweet</a> --><a class="twitter-follow-button" data-show-count="false" href="https://twitter.com/__shenderson__">Follow @__shenderson__</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script></div>

<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

&nbsp;

Today marks the beginning of a long weekend and the end of a 2 day release planning for our software extravaganza (sigh of relief).

Good things:

  * Continued planning for the next 2 months (again).

  * Deployed a [Preso cluster](https://prestodb.io) today to a [DCOS](https://dcos.io/) environment.  Presto is a distributed SQL query engine for big data.  I have been wanting to deploy this into our environment for some time now and today was the day.  I still don't have the connector catalog quite sorted out but it is getting close.

  * Increased amount of team members for our team (we have a backlog for awhile to put it mildly).  What I am trying to say here is if you need a job and are a good programmer, ping me!

Bad things:

  * Worked on project planning for the next 2 months (again).

Projects that I started:

  * Creating a small Bazel, Python demo project for understanding best practices in that environment.

  * Adding in Scala tests to the previous [Bazel Scala/Java mixed demo](https://github.com/bowlofstew/bazel-java-scala) that I started.

Articles that I read:

  * The paper is ["Apache Spark @Scale: A 60 TB+ production use case"](https://code.facebook.com/posts/1671373793181703/apache-spark-scale-a-60-tb-production-use-case/) and covers unsurprisingly, running large scale analytics.  The problem that I am presently tackling is a similar but smaller scale problem.  There are some great tuning gems in there.